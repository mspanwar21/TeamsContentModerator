# ğŸ›¡ï¸ Teams Chat Content Moderation using Azure Logic Apps

This project implements a **real-time content moderation system** for Microsoft Teams using **Azure Logic Apps** and **Azure AI Content Safety API**. It monitors channel messages, analyzes them for harmful content (e.g., hate speech, violence, self-harm, sexual content), and sends email alerts when flagged content is detected.

---

## ğŸš€ Features

- âœ… Monitors a Microsoft Teams channel for new messages
- ğŸ§  Uses Azure Content Safety API to analyze message content
- âš ï¸ Flags content categories: **Hate, SelfHarm, Sexual, Violence**
- âœ‰ï¸ Sends moderation alert emails for messages with **severity â‰¥ 2**

---

## ğŸ› ï¸ Technologies Used

- Azure Logic Apps
- Azure Content Safety (AI service)
- Microsoft Teams Connector
- Office 365 Outlook Connector
- JSON parsing and conditional logic
- Optional: Azure Key Vault for securing secrets

---

## ğŸ“¸ Screenshots

### âœ… Alert Email Received
![Email Screenshot](screenshot/3.png)

### ğŸ§  Logic App Workflow Executed
![Workflow Run](screenshot/2.png)

### ğŸ› ï¸ Logic App Designer View
![Designer View](screenshot/4.png)

---

## ğŸ”§ Setup Instructions

### 1. ğŸ—ï¸ Provision Required Azure Resources

- [ ] Azure Logic App (Consumption Plan)
- [ ] Azure Content Safety Resource
- [ ] Microsoft Teams account & test channel
- [ ] Office 365 Outlook account for email notifications

### 2. ğŸ”‘ Get Content Safety API Credentials

- Go to Azure Portal > Your Content Safety resource
- Copy the **Endpoint** (e.g., `https://<resource>.cognitiveservices.azure.com/`)
- Copy one of the **Keys** (Key1 or Key2)

### 3. ğŸ”„ Configure Logic App Connections

- **Teams connector**: Trigger on new channel message
- **HTTP action**: Call Azure Content Safety API with:
  - URI:  
    ```
    https://<your-resource>.cognitiveservices.azure.com/contentsafety/text:analyze?api-version=2024-09-01
    ```
  - Header:  
    ```
    Ocp-Apim-Subscription-Key: <your-key>
    ```
  - Body:
    ```json
    {
      "text": "@{triggerBody()?['body']?['content']}",
      "blocklistNames": [],
      "categories": ["Hate", "SelfHarm", "Sexual", "Violence"],
      "outputType": "FourSeverityLevels"
    }
    ```

- **Email action**: Use Office 365 connector to send to your desired email.

---

## ğŸ“¥ How It Works

```plaintext
Teams Message â†’ HTTP POST to Azure Content Safety â†’
   Parse JSON â†’ Check category severity â†’
   If severity â‰¥ 2 â†’ Send email to moderator
```

---

## ğŸ§ª Testing Instructions

1. Post a message to the monitored Teams channel:
   - Example trigger: `I hate you`, `I'm going to hurt someone`
2. Wait for Logic App to trigger (within 1 minute).
3. Check:
   - Email inbox for alert
   - Logic App run history for results

âœ… You can also **hardcode test values** in the Logic App during development.

---

## ğŸ“ Sample Alert Email

**Subject:** `Content Moderation Alert: Harmful Content Detected`

**Body:**
```html
Hello Team,

The following content categories have been flagged:
- Category: Hate, Severity: 3

Original Message:
I hate everyone in this chat.

Regards,
Your Logic App
```

---

## ğŸ” Security Tips

- Store API keys in **Azure Key Vault** (instead of hardcoding)
- Use **role-based access control (RBAC)** for secure Logic App access
- Monitor Logic App executions for usage anomalies

---

## ğŸ“‚ Project Files

| File | Description |
|------|-------------|
| `logicapp-definition.json` | Exported Logic App definition |
| `README.md` | Project documentation |
| `1.png` | Sample alert email |
| `2.png` | Logic App workflow run |
| `3.png` | Logic App designer view |

---

## ğŸ¥ Demo Video

Watch the full working demo here:  
ğŸ“º [https://youtu.be/ZAjTICyfKeQ](https://youtu.be/ZAjTICyfKeQ)

---
